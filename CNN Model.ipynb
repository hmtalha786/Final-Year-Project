{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana Leaf Disease Detection and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import keras\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "print(\"Tensorflow version: \",tf.__version__)\n",
    "print(\"Keras version: \",keras.__version__)\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Img_preprocessing(n):\n",
    "    \n",
    "    #step-1: Convert rgb to grayscale\n",
    "    gray_scale=cv2.cvtColor(n, cv2.COLOR_BGR2GRAY )\n",
    "    \n",
    "    \n",
    "    #step-2: Resize the image-----------------\n",
    "    img_size=200\n",
    "    resized_img=cv2.resize(gray_scale,(img_size,img_size)) #resize your image so your all images will have same size\n",
    "    \n",
    "    #step-3:do histogram equalisation to increase contrast of an image-------------\n",
    "    equ = cv2.equalizeHist(resized_img)\n",
    "    \n",
    "    \n",
    "    #step-4:remove noise :using gaussian blur----------------(for smoothing the image)\n",
    "    #blur=cv2.GaussianBlur(equ,(5,5),0)\n",
    "    blur=cv2.medianBlur(equ,5)\n",
    "    \n",
    "    #step-5: Image segmentation for edge detection-------------\n",
    "    #edges = cv2.Canny(equ,100,200) \n",
    "    #edges = cv2.Laplacian(equ, cv2.CV_16S, ksize=3)\n",
    "    grad_x = cv2.Sobel(blur, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    grad_y = cv2.Sobel(blur, cv2.CV_16S, 0, 1, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "    edges = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)   #sobel derivative\n",
    "    \n",
    "    clean_data =edges\n",
    "    return clean_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dir1=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\"\n",
    "catg=['Banana Bacterial Wilt','Black sigatoka disease','Healthy']\n",
    "\n",
    "img_cube=[]\n",
    "image_size=800\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir1,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j)) #convert rgb image to gray scale image\n",
    "        final_data=Img_preprocessing(img_arr)\n",
    "        img_cube.append([final_data,label])\n",
    "print(\"Length of your dataset: \",len(img_cube))\n",
    "print(\"Whole image data in array format:\\n\",img_cube[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='C:\\Users\\Muhammad Talha\\Desktop\\Project\\img_seg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_cube[3][0],cmap='gray')\n",
    "img_cube[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_cube[350][0],cmap='gray')\n",
    "img_cube[350][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cube[350][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_cube[500][0],cmap='gray')\n",
    "img_cube[500][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now i am trying to shuffle the data \n",
    "random.shuffle(img_cube)\n",
    "\n",
    "for i in img_cube[:10]:\n",
    "    print(i[1])\n",
    "\n",
    "#these are the random labels generated \n",
    "#as i have 3 types of image folder in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "feature=[]\n",
    "target=[]\n",
    "for i in img_cube:\n",
    "    flat=i[0].flatten()\n",
    "    feature.append(flat)\n",
    "for i in img_cube:\n",
    "    target.append(i[1])\n",
    "    \n",
    "len(feature),len(target)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.25,random_state=42)\n",
    "\n",
    "clf1=SVC().fit(x_train,y_train)\n",
    "y_pred=clf1.predict(x_test)\n",
    "\n",
    "print(\"*-*\"*100)\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "print(\"*-*\"*100)\n",
    "\n",
    "feature[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels={0:'BBW',1:'BSD',2:'Healthy'}\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred,),cmap=\"YlGnBu_r\", xticklabels=['BBW', 'BSD','Healthy'],yticklabels=['BBW', 'BSD','Healthy'])\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "k=classification_report(y_test,y_pred,target_names=['BBW', 'BSD','Healthy'])\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Accuracy without doing preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\"\n",
    "catg=['Banana Bacterial Wilt','Black sigatoka disease','Healthy']\n",
    "\n",
    "img_cube2=[]\n",
    "image_size=500\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir2,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j))\n",
    "        gray_scale=cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY )\n",
    "        resized_img=cv2.resize(gray_scale,(200,200))\n",
    "        img_cube2.append([resized_img,label])\n",
    "\n",
    "random.shuffle(img_cube2)\n",
    "\n",
    "feature2=[]\n",
    "target2=[]\n",
    "for i in img_cube2:\n",
    "    flat=i[0].flatten()\n",
    "    feature2.append(flat)\n",
    "for i in img_cube2:\n",
    "    target2.append(i[1])\n",
    "    \n",
    "#len(feature2),len(target2)\n",
    "\n",
    "x_train2,x_test2,y_train2,y_test2=train_test_split(feature2,target2,test_size=0.25,random_state=42)\n",
    "\n",
    "clf1=SVC().fit(x_train2,y_train2)\n",
    "y_pred2=clf1.predict(x_test2)\n",
    "\n",
    "print(\"*-*\"*100)\n",
    "print(accuracy_score(y_test2,y_pred2)*100)\n",
    "print(\"*-*\"*100)\n",
    "\n",
    "feature[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Accuracy with colored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir2=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\"\n",
    "catg=['Banana Bacterial Wilt','Black sigatoka disease','Healthy']\n",
    "\n",
    "img_cube2=[]\n",
    "image_size=500\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir2,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j))\n",
    "        #gray_scale=cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY )\n",
    "        resized_img=cv2.resize(img_arr,(200,200))\n",
    "        img_cube2.append([resized_img,label])\n",
    "\n",
    "random.shuffle(img_cube2)\n",
    "\n",
    "feature2=[]\n",
    "target2=[]\n",
    "for i in img_cube2:\n",
    "    flat=i[0].flatten()\n",
    "    feature2.append(flat)\n",
    "for i in img_cube2:\n",
    "    target2.append(i[1])\n",
    "    \n",
    "#len(feature2),len(target2)\n",
    "feature2 = np.array(feature2)/ 255.0\n",
    "\n",
    "x_train2,x_test2,y_train2,y_test2=train_test_split(feature2,target2,test_size=0.25,random_state=42)\n",
    "\n",
    "clf1=SVC().fit(x_train2,y_train2)\n",
    "y_pred2=clf1.predict(x_test2)\n",
    "\n",
    "print(\"*-*\"*100)\n",
    "print(accuracy_score(y_test2,y_pred2)*100)\n",
    "print(\"*-*\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_aug=ImageDataGenerator(  rotation_range=40,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              channel_shift_range=0.2,\n",
    "                              zoom_range=0.2,\n",
    "                              fill_mode=\"nearest\",\n",
    "                              horizontal_flip=True,\n",
    "                              vertical_flip=True,      \n",
    "                             )         \n",
    "s=data_aug.flow(x_train,y_train, batch_size = 32)\n",
    "s[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for BBW class\n",
    "i=0\n",
    "for batch in data_aug.flow_from_directory(directory=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\\\",\n",
    "                                          classes=['Banana Bacterial Wilt'],\n",
    "                                          batch_size=32,\n",
    "                                          target_size=(500,500),\n",
    "                                          color_mode='rgb',\n",
    "                                          save_to_dir='C:\\Users\\Muhammad Talha\\Desktop\\Project\\Banana Bacterial Wilt',\n",
    "                                          save_prefix='aug',\n",
    "                                          save_format='png'):\n",
    "    i += 1\n",
    "    if i>19: #for a particular class it creates 20 image for image in that class\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for BSD class\n",
    "i=0\n",
    "for batch in data_aug.flow_from_directory(directory=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\\\",\n",
    "                                          classes=['Black sigatoka disease'],\n",
    "                                          batch_size=32,\n",
    "                                          target_size=(500,500),\n",
    "                                          color_mode='rgb',\n",
    "                                          save_to_dir='C:\\Users\\Muhammad Talha\\Desktop\\Project\\Black sigatoka disease',\n",
    "                                          save_prefix='aug',\n",
    "                                          save_format='png'):\n",
    "    i += 1\n",
    "    if i>19: #for a particular class it creates 20 image for image in that class\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for healthy class\n",
    "i=0\n",
    "for batch in data_aug.flow_from_directory(directory=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\\\",\n",
    "                                          classes=['Healthy'],\n",
    "                                          batch_size=32,\n",
    "                                          target_size=(500,500),\n",
    "                                          color_mode='rgb',\n",
    "                                          save_to_dir='C:\\Users\\Muhammad Talha\\Desktop\\Project\\Healthy',\n",
    "                                          save_prefix='aug',\n",
    "                                          save_format='png'):\n",
    "    i += 1\n",
    "    if i>19: #for a particular class it creates 20 image for image in that class\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Extract the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir1=\"C:\\Users\\Muhammad Talha\\Desktop\\Project\"\n",
    "catg=['Banana Bacterial Wilt','Black sigatoka disease','Healthy']\n",
    "\n",
    "img_cube3=[]\n",
    "#image_size=800\n",
    "\n",
    "for i in catg: #this will take the folder names as we call it as categoris\n",
    "    path=os.path.join(dir1,i)\n",
    "    label=catg.index(i)\n",
    "    for j in os.listdir(path): #this will take the actual path of each folder image\n",
    "        img_arr=cv2.imread(os.path.join(path,j)) #convert rgb image to gray scale image\n",
    "        #gray_img=cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY )\n",
    "        final_data=cv2.resize(img_arr,(100,100))\n",
    "        img_cube3.append([final_data,label])\n",
    "        \n",
    "img_cube3[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat3=[]\n",
    "tar3=[]\n",
    "for i,j in img_cube3:\n",
    "    feat3.append(i)\n",
    "    tar3.append(j)\n",
    "x=np.array(feat3)\n",
    "x=x/255.0 #as scaling the values between 0 to 1 becuz lesser the values faster will be the calculation\n",
    "y=np.array(tar3)\n",
    "plt.imshow(x[500],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.30)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train=to_categorical(y_train, dtype =\"float64\")\n",
    "#y_test=to_categorical(y_test,  dtype =\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dtype,y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train2=x_train2.reshape(len(x_train2),200,200,1) #these two lines are not applicable for colored image we can directly fit those values\n",
    "#x_test2=x_test2.reshape(len(x_test2),200,200,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of horizontal shift image augmentation\n",
    "from numpy import expand_dims\n",
    "\n",
    "# load the image\n",
    "img = load_img(\"C:\\Users\\Muhammad Talha\\Desktop\\Project\\Healthy\\9.png\")\n",
    "# convert to numpy array\n",
    "data = img_to_array(img)\n",
    "# expand dimension to one sample\n",
    "samples = expand_dims(data, 0)\n",
    "\n",
    "# prepare iterator\n",
    "it = data_aug.flow(samples, batch_size=9)\n",
    "# generate samples and plot\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # generate batch of images\n",
    "    batch = it.next()\n",
    "    # convert to unsigned integers for viewing\n",
    "    image = batch[0].astype('uint8')\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn2=Sequential()\n",
    "\n",
    "#convolutional layer-1\n",
    "cnn2.add(Conv2D(32, kernel_size=(3, 3), activation='relu',  padding='same'))\n",
    "cnn2.add(MaxPooling2D(2,2))\n",
    "\n",
    "#convolutional layer-2\n",
    "cnn2.add(Conv2D(64, kernel_size=(3, 3), activation='relu',  padding='same'))\n",
    "cnn2.add(MaxPooling2D(2,2))\n",
    "\n",
    "#convolutional layer-3\n",
    "cnn2.add(Conv2D(128, kernel_size=(3, 3), activation='relu',  padding='same'))\n",
    "cnn2.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "#convolutional layer-4\n",
    "cnn2.add(Conv2D(256, kernel_size=(3, 3), activation='relu',  padding='same'))\n",
    "cnn2.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "#flatten layer\n",
    "cnn2.add(Flatten(input_shape=x_train.shape[1:] ))\n",
    "\n",
    "\n",
    "cnn2.add(Dense(256,activation='relu'))\n",
    "\n",
    "#densly connected layer\n",
    "cnn2.add(Dense(128,activation='relu'))\n",
    "\n",
    "#output layer\n",
    "cnn2.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "cnn2.compile(optimizer='Adagrad',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "#logit=true when we not use any normalization for last layer that means if we don't apply any act. fun then keep logit=true0----\n",
    "#with RMSPROP got 74-72%\n",
    "#SGD found 57%\n",
    "\n",
    "\n",
    "\n",
    "history2=cnn2.fit(  x_train,\n",
    "          y_train,\n",
    "          verbose=1,\n",
    "          epochs=200,  #20\n",
    "          batch_size=32,  #15\n",
    "          validation_data=(x_test,y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Predictions on the Model\n",
    "\n",
    "score = cnn2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in range(len(x_test)):\n",
    "        y_pred.append(cnn2.predict(x_test[i].reshape(1,100,100,3)))\n",
    "        \n",
    "len(y_test),len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10]  #to get max probability value we use argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]\n",
    "for i in range(len(x_test)):\n",
    "    result.append(np.argmax(y_pred[i],axis=1)) #it will take index value for which value is maxiumum of that array\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.summary()\n",
    "\n",
    "\n",
    "y_pred2=result\n",
    "\n",
    "print(\"*-*\"*40)\n",
    "print(\"Accuracy Found: \",accuracy_score(y_test,np.array(y_pred2)))\n",
    "#using adam accuracy was 83%\n",
    "#using adadelta accuracy was 89%\n",
    "print(\"*-*\"*40)\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,np.array(y_pred2))) \n",
    "print(\"*-*\"*40)\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,np.array(y_pred2)))\n",
    "print(\"*-*\"*40)\n",
    "\n",
    "#plt.figure(figsize=(15,9))\n",
    "plt.title('Loss Comparison',fontsize=20)\n",
    "plt.plot(history2.history['loss'],)\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.legend(['Training Loss','Validation Loss'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(15,9))\n",
    "plt.title('Accuracy comparison ',fontsize=20)\n",
    "plt.plot(history2.history['accuracy'],)\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.legend(['Training Acc','Validation Acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle and joblib\n",
    "from keras.models import save_model\n",
    "#model.save(\"Banana_leaf_classification.h5\") \n",
    "\n",
    "\n",
    "# Save the model\n",
    "#filepath = 'C:\\Users\\Muhammad Talha\\Desktop\\Project'\n",
    "#save_model(cnn2, filepath)\n",
    "\n",
    "\n",
    "cnn2.save(\"BananaLeaf_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=r'C:\\Users\\Muhammad Talha\\Desktop\\Project\\Deploy'\n",
    "cnn2.save(\"C:/Users/sahoo/Desktop/Banana_leaf_disease/Deploy/BananaLeaf_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model\n",
    "\n",
    "#filepath = 'C:\\Users\\Muhammad Talha\\Desktop\\Project'\n",
    "mymodel = load_model(\"BananaLeaf_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prediction(result,model): #type of result should be an array\n",
    "    arr=cv2.resize(result,(100,100))\n",
    "    y_prediction= mymodel.predict(arr.reshape(1,100,100,3))\n",
    "    result=np.argmax(y_prediction,axis=1) #take the index value of that array which value is maximum\n",
    "    if result==0:\n",
    "        print('It has a disease called Black Bacterial Wilt')\n",
    "    elif result==1:\n",
    "        print('It has a disease called Black Sigatoka Disease')\n",
    "    elif result==2:\n",
    "        print('Wohh!!! It is a healthy Leaf')\n",
    "        \n",
    "prediction(x_test[309],mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[309]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be done in phase 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
